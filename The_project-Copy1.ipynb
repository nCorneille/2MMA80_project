{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports and loading the dataset</h2><br>\n",
    "This code cell handles all library and dataset importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2062, 64, 64), shape of Y: (2062, 10)\n",
      "Y[0]=[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Y[600]=[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    " # standard libraries\n",
    "import math, os, time, glob, random\n",
    "import numpy as np\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# progress bars\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn # lets not write out torch.nn every time\n",
    "import torch.nn.functional as F # functional versions of the modules in torch.nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load the stored numpy arrays\n",
    "X = np.load(\"./sign-language-digits-dataset/X.npy\")\n",
    "Y = np.load(\"./sign-language-digits-dataset/Y.npy\")\n",
    "\n",
    "# lets inspect their shape\n",
    "print(f\"Shape of X: {X.shape}, shape of Y: {Y.shape}\")\n",
    "\n",
    "# Looks like we have 2062 samples, the images are 64x64 grayscale\n",
    "# the labels look like they are stored as a probability distribution (a.k.a. one-hot encoding) over the 10 classes:\n",
    "print(f\"Y[0]={Y[0]}, Y[600]={Y[1000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the one-hot encoding (i.e. elements of {0,1}^10) to elements of {0,...,9}. This is done using the fact that only one vector element is nonzero, which implies that the argmax returns the index of the 1 (note that computer sequences start at zero so argmax maps into {0,...,9})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y[0]=0, Y[600]=4\n"
     ]
    }
   ],
   "source": [
    "Y = np.argmax(Y, -1)\n",
    "\n",
    "print(f\"Y[0]={Y[0]}, Y[600]={Y[1000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets visualize some of the samples\n",
    "show = (100, 600, 1500, 2000)\n",
    "plt.figure(figsize=[4*len(show), 4])\n",
    "\n",
    "for i in range(len(show)):\n",
    "    plt.subplot(1, len(show), i+1)\n",
    "    plt.imshow(X[show[i]], cmap='gray_r')\n",
    "    plt.text(4, 4, f\"{Y[show[i]]}\", va='top' ,color='C1', fontsize=48)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the dataset into training and testing data, and set a random seed to make reproducible results. To split the dataset, we choose a random starting point such that X[start:end] has the right amount of elements. The testing dataset will then be defined as 'test dataset = dataset \\ training dataset' (but in a way which NumPy understands), where \\ denotes set theoretic difference. The random split is implemented in order to avoid overfitting on one particular split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Universal constants'\n",
    "RANDOM_SEED = 694201337\n",
    "NUMBER_OF_CLASSES = 10 # this avoids 'magic numbers' later in the code\n",
    "DATASET_SIZE = X.shape[0]\n",
    "\n",
    "# Hyper parameters\n",
    "PERCENTAGE_TEST = 30\n",
    "LEARNING_RATE = 0.007\n",
    "BATCH_SIZE = 4\n",
    "N_EPOCHS_1 = 40\n",
    "N_EPOCHS_2 = 27\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Custom dataset split function before I realized that torch.utils.data.random_split exists\n",
    "def split_train_test(X,Y):\n",
    "    training_elements = round(DATASET_SIZE * (1-PERCENTAGE_TEST/100))\n",
    "    start_point = random.randint(0, DATASET_SIZE - training_elements)\n",
    "\n",
    "    X_train = X[start_point:start_point+training_elements]\n",
    "    Y_train = Y[start_point:start_point+training_elements]\n",
    "\n",
    "    X_test = np.concatenate((X[0:start_point], X[start_point+training_elements:]), axis=0)\n",
    "    Y_test = np.concatenate((Y[0:start_point], Y[start_point+training_elements:]), axis=0)\n",
    "\n",
    "    #terminate the program if train size + test size unequal tot DATASET_SIZE\n",
    "    assert(not DATASET_SIZE - X_train.shape[0] - X_test.shape[0])\n",
    "    \n",
    "    return (X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# Make the data readable to PyTorch\n",
    "X = torch.tensor(X).unsqueeze(1).to(device)\n",
    "Y = torch.tensor(Y).to(device)\n",
    "dataset = torch.utils.data.TensorDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 6, 7, 8], [3, 9], array([0, 1, 2, 6, 7, 8]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on list slicing/concatenation\n",
    "A = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "#List slicing is non inclusive at the end\n",
    "A[0:3]+A[6:9], [A[3],A[9]], np.concatenate((np.array(A[0:3]),np.array(A[6:9])),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The network architecture, and training the network</h2>\n",
    "\n",
    "The network we will use is based on the LeNet-5 architecture (see, for example, https://towardsdatascience.com/implementing-yann-lecuns-lenet-5-in-pytorch-5e05a0911320; in fact a lot of code in this project is based on this article, this article will be refered to as [LeNet-5]). However we will make some modifications, in particular we will use ReLU activation functions rather than tanh. Furthermore the pictures in our dataset are twice the size of the ones in the MNIST dataset (for which LeNet-5 was created), to deal with this the dimensions of some layers have been modified. <br>\n",
    "The other architecture is based on the following github page which solves a similar problem: https://github.com/francislata/Sign-Language-Digits-CNN/blob/master/model.py. <br>\n",
    "To keep track of the dimensions of each layer, we use the following formula for pooling and convolution layers (see the PyTorch documentation):\n",
    "![image](https://i.imgur.com/49clMN9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_clone(nn.Module): # Class inherits from nn.Module\n",
    "    \n",
    "    def __init__(self, number_of_classes):\n",
    "        super(LeNet5_clone, self).__init__()\n",
    "        \n",
    "        # We separate the network into a feature extractor and classifier \n",
    "        \n",
    "        # This sequence contains the convolution layers, and works with picture data\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # in: 1×64×64\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.ReLU(), #6×60×60\n",
    "            nn.AvgPool2d(kernel_size=2), #6×30×30\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.ReLU(), #16×26×26\n",
    "            nn.AvgPool2d(kernel_size=2), #16×13×13\n",
    "            nn.Conv2d(in_channels=16, out_channels=64, kernel_size=5, stride=1),\n",
    "            nn.ReLU() #64×9×9\n",
    "        )\n",
    "        \n",
    "        # This sequence contains the fully connected layers and works on flattened data\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=64*9*9, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=number_of_classes),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        # We transform the logits to probits (i.e. a probability mass function)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        return logits,probs\n",
    "\n",
    "class NN_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN_2, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # in: 1×64×64\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(), # 32×64×64\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), # 32×32×32\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(), # 64×32×32\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), # 64×16×16\n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(), # 128×16×16\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2), # 128×8×8\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128*8*8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        return logits,probs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5_clone(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5184, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "NN_2(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "The LeNet-5 clone has 464626 parameters\n",
      "The second network has 4354442 parameters\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# We use our model based on LeNet-5 in combinations with the\n",
    "# SGD optimizer using a cross-entropy loss function\n",
    "model_1 = LeNet5_clone(NUMBER_OF_CLASSES).to(device)\n",
    "model_2 = NN_2().to(device)\n",
    "\n",
    "optimizer_1 = torch.optim.SGD(model_1.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_2 = torch.optim.SGD(model_2.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "print(model_1)\n",
    "print(model_2)\n",
    "\n",
    "print(f\"The LeNet-5 clone has {sum(p.numel() for p in model_1.parameters())} parameters\")\n",
    "print(f\"The second network has {sum(p.numel() for p in model_2.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the second network has more parameters by a factor of almost 10.\n",
    "\n",
    "The following function defines the training sequence and is based on the same article that creates a clone of the LeNet-5 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    '''\n",
    "    returns the current time in 'year_month_day_hour_minutes_seconds'\n",
    "    '''\n",
    "    t = time.localtime()\n",
    "    return time.strftime('%Y_%b_%d_%H_%M_%S', t)\n",
    "\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    Copied from [LeNet-5], comments added for clarity\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval() # Put the model in evaluation mode\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            \n",
    "            # We get the softmax of the model predictions and then convert it to\n",
    "            # the expected answer, note that this is done in a vectorized manner\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "            \n",
    "            \n",
    "            # We add the size of the batch to n and add the\n",
    "            # number of correct predictions to correct_pref\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    Function for plotting training and validation losses\n",
    "    Copied from [LeNet-5], comments added for clarity\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # The losses are converted to NumPy format\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "    \n",
    "    # Standard MatPlotLib plotting procedure\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')\n",
    "\n",
    "def plot_accuracy(train_losses, valid_losses):\n",
    "    '''\n",
    "    Copy-paste of plot_losses\n",
    "    This violates the \"don't repeat yourself\" coding convention \n",
    "    (but I can't be asked to pass a third parameter into the plot function)\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # The losses are converted to NumPy format\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "    \n",
    "    # Standard MatPlotLib plotting procedure\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training accuracy') \n",
    "    ax.plot(valid_losses, color='red', label='Validation accuracy')\n",
    "    ax.set(title=\"Accuracy over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Accuracy') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    Copied from [LeNet-5], comments added for clarity\n",
    "    \n",
    "    All the PyTorch specific stuff (models, optimizers, etc.) is passed\n",
    "    (hopefully as a pointer but that depends on how Python handles this)\n",
    "    to the function in order to make it easy to try out other models etc.\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # A running loss is used to keep track of losses across batches\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad() # Reset optimizer gradients\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # Forward pass, i.e. make the model predict stuff\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass, i.e. update the weights using backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # epoch_loss is the mean of the individual batch losses\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    Copied from [LeNet-5], comments added for clarity\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # A running loss is used to keep track of losses across batches\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # Forward pass and update running loss\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        \n",
    "        # As we are validating, there is no backwards pass\n",
    "\n",
    "    # We again take the mean over all batches\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss\n",
    "\n",
    "\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    Copied from [LeNet-5], comments added for clarity\n",
    "    '''\n",
    "    \n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    train_accu = []\n",
    "    valid_accu = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # Train the model, then add the losses to the loss array\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validate the model on the validation dataset\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "        \n",
    "        \n",
    "        # TODO: this is very inefficient\n",
    "        train_acc = get_accuracy(model, train_loader, device=device)\n",
    "        valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "        \n",
    "        train_accu.append(train_acc)\n",
    "        valid_accu.append(valid_acc)\n",
    "\n",
    "        # Print the loss and accuracy when print_every|epoch\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "                \n",
    "            print(f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    plot_accuracy(train_accu, valid_accu)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses), (train_accu, valid_accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NN_2:\n\tMissing key(s) in state_dict: \"classifier.4.weight\", \"classifier.4.bias\". \n\tsize mismatch for feature_extractor.0.weight: copying a param with shape torch.Size([6, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for feature_extractor.0.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for feature_extractor.3.weight: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for feature_extractor.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feature_extractor.6.weight: copying a param with shape torch.Size([64, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for feature_extractor.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([84, 5184]) from checkpoint, the shape in current model is torch.Size([512, 8192]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for classifier.2.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n\tsize mismatch for classifier.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-29b59d3d1f77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mnetwork_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0moptimizer_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 829\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m    830\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m    831\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NN_2:\n\tMissing key(s) in state_dict: \"classifier.4.weight\", \"classifier.4.bias\". \n\tsize mismatch for feature_extractor.0.weight: copying a param with shape torch.Size([6, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for feature_extractor.0.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for feature_extractor.3.weight: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for feature_extractor.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feature_extractor.6.weight: copying a param with shape torch.Size([64, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for feature_extractor.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([84, 5184]) from checkpoint, the shape in current model is torch.Size([512, 8192]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for classifier.2.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n\tsize mismatch for classifier.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "test_losses = []\n",
    "\n",
    "# Calculate the size of the validation dataset using hyperparameters\n",
    "test_size = round(DATASET_SIZE * PERCENTAGE_TEST/100)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, \n",
    "            [DATASET_SIZE - test_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=False)\n",
    "\n",
    "path_1 = f\"Lenet-5-clone_LR={LEARNING_RATE}_BS={BATCH_SIZE}_EPOCH={N_EPOCHS_1}.pth\"\n",
    "path_2 = f\"Network-2_LR={LEARNING_RATE}_BS={BATCH_SIZE}_EPOCH={N_EPOCHS_2}.pth\"\n",
    "\n",
    "if not os.path.exists(path_1):\n",
    "    model_1, optimizer_1, _, _ = training_loop(model_1, criterion, optimizer_1,\n",
    "                                        train_loader, valid_loader, N_EPOCHS_1, device)\n",
    "\n",
    "    # Save the model at the end of training\n",
    "    torch.save({\n",
    "        'epoch': N_EPOCHS_1,\n",
    "        'model_state_dict': model_1.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_1.state_dict(),\n",
    "    }, path_1)\n",
    "else:\n",
    "    network_1 = torch.load(path_1)\n",
    "    \n",
    "    model_1.load_state_dict(network_1['model_state_dict'])\n",
    "    optimizer_1.load_state_dict(network_1['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "if not os.path.exists(path_2):\n",
    "    model_2, optimizer_2, _, _ = training_loop(model_2, criterion, optimizer_2,\n",
    "                                        train_loader, valid_loader, N_EPOCHS_2, device)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': N_EPOCHS_2,\n",
    "        'model_state_dict': model_2.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_2.state_dict(),\n",
    "    }, path_2)\n",
    "else:\n",
    "    network_2 = torch.load(path_2)\n",
    "    \n",
    "    model_2.load_state_dict(network_2['model_state_dict'])\n",
    "    optimizer_2.load_state_dict(network_2['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some of the photos including the model's prediction (copied from [LeNet-5])\n",
    "ROW_IMG = 5\n",
    "N_ROWS = 5\n",
    "\n",
    "# Reasonably standard MatPlotLib stuff\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(valid_dataset[index][0].squeeze(0), cmap='gray_r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_1.eval()\n",
    "        # This one includes the prediction of the LeNet-5 clone\n",
    "        _, probs = model_1(valid_dataset[index][0].unsqueeze(0))\n",
    "        \n",
    "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
    "    \n",
    "    plt.title(title, fontsize=7)\n",
    "fig.suptitle('LeNet-5 clone network - predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(valid_dataset[index][0].squeeze(0), cmap='gray_r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_2.eval()\n",
    "        # This one include the prediction of the second network\n",
    "        _, probs = model_2(valid_dataset[index][0].unsqueeze(0))\n",
    "        \n",
    "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
    "    \n",
    "    plt.title(title, fontsize=7)\n",
    "fig.suptitle('Second network - predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will contain the relevant graphs (so the grader doesn't have to spend significant time retraining the networks)<br>\n",
    "These images contain the cross-entropy loss and accuracy of the LeNet-5 clone network as a function of the epoch\n",
    "![image](https://i.imgur.com/Cnqf52n.png)\n",
    "![image](https://i.imgur.com/UfYtpuy.png) <br>\n",
    "The following images contain the cross-entropy loss and accuracy of the second network as a function of the epoch\n",
    "![image](https://i.imgur.com/bBspZ8Y.png)\n",
    "![image](https://i.imgur.com/L0czAa1.png)\n",
    "It can be seen (by looking very closely, or by checking the logs while training the network) that the LeNet-5 clone peaks at around 90% accuracy on validation data, and the second network peaks at around 92% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experiment</h2>\n",
    "We will now validate both networks on rotated data. First we need to rotate the images, we will do so by 90 degrees counterclockwise. This is done using the torch.rot90 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape = (..., 1, 64, 64) so we want to rotate the (2,3)-axis\n",
    "X = torch.rot90(X, 1, [2,3])\n",
    "\n",
    "show = (100, 600, 1500, 2000)\n",
    "plt.figure(figsize=[4*len(show), 4])\n",
    "\n",
    "for i in range(len(show)):\n",
    "    plt.subplot(1, len(show), i+1)\n",
    "    plt.imshow(X.squeeze(1)[show[i]], cmap='gray_r')\n",
    "    plt.text(4, 4, f\"{Y[show[i]]}\", va='top' ,color='C1', fontsize=48)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now show the predictions on a rotated version of the dataset\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(torch.rot90(valid_dataset[index][0].squeeze(0),1,[0,1]), cmap='gray_r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_1.eval()\n",
    "        # This one includes the prediction of the LeNet-5 clone\n",
    "        _, probs = model_1(torch.rot90(valid_dataset[index][0].unsqueeze(0),1,[2,3]))\n",
    "        \n",
    "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
    "    \n",
    "    plt.title(title, fontsize=7)\n",
    "fig.suptitle('LeNet-5 clone network - predictions, rotated');\n",
    "\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(torch.rot90(valid_dataset[index][0].squeeze(0),1,[0,1]), cmap='gray_r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_2.eval()\n",
    "        # This one include the prediction of the second network\n",
    "        _, probs = model_2(torch.rot90(valid_dataset[index][0].unsqueeze(0),1,[2,3]))\n",
    "        \n",
    "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
    "    \n",
    "    plt.title(title, fontsize=7)\n",
    "fig.suptitle('Second network - predictions, rotated');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the network does not work at all on rotated data. This is as expected, as no parameters are dedicated to learning about rotations (as there isn't any rotated data to begin with). A way to solve this is by implementing an SE(2)-equivariant CNN on our data. This can be done using, for example, the e2cnn library (https://github.com/QUVA-Lab/e2cnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
