{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "Training neural networks takes a long time, so it would be a good idea to regularly save your progress. In this notebooks we will go over how we can save and load our models and training progress. Lets do our usual imports and define a model for us to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import math, os, time, glob\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# progress bars\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn # lets not write out torch.nn every time\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 32 # how many hidden units we want\n",
    "\n",
    "network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, hidden), # = x A^T + b\n",
    "    torch.nn.ReLU(), # = ReLU(x A^T + b)\n",
    "    torch.nn.Linear(hidden, 1, bias=False), # = ReLU(x A^T + b) C^T\n",
    ")\n",
    "\n",
    "network = network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a whole Model\n",
    "\n",
    "In order to save an entire model we write it to a file as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then restore it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2 = torch.load('model.pth')\n",
    "\n",
    "network2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of the above approach is that it depends on the current environment having the exact same definition of all the modules used when saving the model. As long as you stick to this environment with its specific version of PyTorch and do not define your own modules saving the entire model is fine. In more advanced scenarios it is recommended to only save your model's parameters, more details are available at <https://pytorch.org/tutorials/beginner/saving_loading_models.html>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "\n",
    "During training we might not want to just save the model or its parameters but also anciliar information like what epoch we are in, the state of the optimizer, etc. In the example below we save the model and optimizer parameters in file tagged with a timestamp.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    t = time.localtime()\n",
    "    return time.strftime('%Y_%b_%d_%H_%M_%S', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set up our training process in the usual manner\n",
    "\n",
    "X = torch.arange(0., 1., step=0.01, device=device)\n",
    "Y = 0.6 * torch.sin(6*X) * torch.sin(3*X+1) + 0.25\n",
    "X = X.unsqueeze(-1)\n",
    "Y = Y.unsqueeze(-1)\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3d98a8bb574aff900aa66093d2b449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can start training\n",
    "for epoch in trange(1, EPOCHS+1):\n",
    "    \n",
    "    network.train() \n",
    "    \n",
    "    for x, y in iter(loader):\n",
    "        optimizer.zero_grad() \n",
    "        prediction = network(x) \n",
    "        loss = (y - prediction).pow(2).sum() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "    \n",
    "    # Save every few epochs\n",
    "    if epoch % 200 == 0 or epoch == EPOCHS:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': network.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, f\"check_{timestamp()}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the checkpoint files we have written to disk using `glob`. Calling `glob` gives us a list of files that match the desired filter, we then sort that list by name using `sorted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['check_2021_Sep_19_17_24_39.pth',\n",
       " 'check_2021_Sep_19_17_24_40.pth',\n",
       " 'check_2021_Sep_19_17_24_41.pth',\n",
       " 'check_2021_Sep_19_17_24_42.pth',\n",
       " 'check_2021_Sep_19_17_24_44.pth']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob.glob('check_*.pth')) # glob yields a list of the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to store too many checkpoint files so we will delete all except the 3 newest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = sorted(glob.glob('check_*.pth'))\n",
    "for file in checkpoints[:-3]:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us load the newest checkpoint and restore our model and optimizer to their previous state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from epoch 1000\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoints[-1])\n",
    "\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "last_epoch = checkpoint['epoch']\n",
    "print(f\"Restored from epoch {last_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can continue training from where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b3a6c5a52d4fc09ef60ada629016ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in trange(last_epoch, last_epoch+EPOCHS):\n",
    "    \n",
    "    network.train() \n",
    "    \n",
    "    for x, y in iter(loader):\n",
    "        optimizer.zero_grad() \n",
    "        prediction = network(x) \n",
    "        loss = (y - prediction).pow(2).sum() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "    \n",
    "    # Save every few epochs\n",
    "    if epoch % 200 == 0 or epoch == EPOCHS:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': network.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, f\"check_{timestamp()}.pth\")\n",
    "        \n",
    "\n",
    "# clean up checkpoint files\n",
    "checkpoints = sorted(glob.glob('check_*.pth'))\n",
    "for file in checkpoints[:-3]:\n",
    "    os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
